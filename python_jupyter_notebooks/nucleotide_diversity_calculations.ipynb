{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import shutil\n",
    "import os\n",
    "import warnings\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           run_id        probe_id  \\\n",
      "0  wtchgD00001556  Geno1a_probe_1   \n",
      "1  wtchgD00001556  Geno1a_probe_2   \n",
      "2  wtchgD00001556  Geno1a_probe_3   \n",
      "3  wtchgD00001556  Geno1a_probe_4   \n",
      "4  wtchgD00001556  Geno1a_probe_5   \n",
      "\n",
      "                                      probe_sequence  \\\n",
      "0  CCAGCCCCCTGATGGGGGCGACACTCCACCATGAATCACTCCCCTG...   \n",
      "1  CTTCACGCAGAAAGCGTCTAGCCATGGCGTTAGTATGAGTGTCGTG...   \n",
      "2  CCCCCCCTCCCGGGAGAGCCATAGTGGTCTGCGGAACCGGTGAGTA...   \n",
      "3  GGACGACCGGGTCCTTTCTTGGATCAACCCGCTCAATGCCTGGAGA...   \n",
      "4  CGCAAGACTGCTAGCCGAGTAGTGTTGGGTCGCGAAAGGCCTTGTG...   \n",
      "\n",
      "                     matched_reference_position_list  \\\n",
      "0  [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 1...   \n",
      "1  [62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 7...   \n",
      "2  [120, 121, 122, 123, 124, 125, 126, 127, 128, ...   \n",
      "3  [180, 181, 182, 183, 184, 185, 186, 187, 188, ...   \n",
      "4  [240, 241, 242, 243, 244, 245, 246, 247, 248, ...   \n",
      "\n",
      "                         reference_msa_position_list  \\\n",
      "0  [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 1...   \n",
      "1  [62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 7...   \n",
      "2  [121, 122, 123, 124, 125, 126, 127, 128, 129, ...   \n",
      "3  [181, 182, 183, 184, 185, 186, 187, 188, 189, ...   \n",
      "4  [242, 243, 244, 245, 246, 247, 248, 249, 250, ...   \n",
      "\n",
      "                   base_reference_read_position_list  \\\n",
      "0  [None, None, None, None, None, None, 1, 2, 3, ...   \n",
      "1  [55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 6...   \n",
      "2  [113, 114, 115, 116, 117, 118, 119, 120, 121, ...   \n",
      "3  [173, 174, 175, 176, 177, 178, 179, 180, 181, ...   \n",
      "4  [233, 234, 235, 236, 237, 238, 239, 240, 241, ...   \n",
      "\n",
      "                    base_reference_msa_read_sequence  \\\n",
      "0  CCAGCCCCCTGATGGGGGCGACACTCCACCATGAATCACTCCCCTG...   \n",
      "1  ----------------------------------------------...   \n",
      "2  ----------------------------------------------...   \n",
      "3  ----------------------------------------------...   \n",
      "4  ----------------------------------------------...   \n",
      "\n",
      "               base_reference_msa_reference_sequence  \\\n",
      "0  ------CCCTGATGGGGGCGACACTCCACCATGAATCACTCCCCTG...   \n",
      "1  CCCTGATGGGGGCGACACTCCACCATGAATCACTCCCCTGTGAGGA...   \n",
      "2  CCCTGATGGGGGCGACACTCCACCATGAATCACTCCCCTGTGAGGA...   \n",
      "3  CCCTGATGGGGGCGACACTCCACCATGAATCACTCCCCTGTGAGGA...   \n",
      "4  CCCTGATGGGGGCGACACTCCACCATGAATCACTCCCCTGTGAGGA...   \n",
      "\n",
      "                     base_reference_alignment_region  \\\n",
      "0  ------CCCTGATGGGGGCGACACTCCACCATGAATCACTCCCCTG...   \n",
      "1  CTTCACGCAGAAAGCGTCTAGCCATGGCGTTAGTATGAGTGTCGTG...   \n",
      "2  CCCCCCCTCCCGGGAGAGCCATAGTGGTCTGCGGAACCGGTGAGTA...   \n",
      "3  GGACGACCGGGTCCTTTCTTGGATCAACCCGCTCAATGCCTGGAGA...   \n",
      "4  CGCAAGATCGCTAGCCGAGTAGTGTTGGGTCGCGAAAGGCCTTGTG...   \n",
      "\n",
      "                                      probe_from_msa  ... normalized_coverage  \\\n",
      "0  CCAGCCCCCTGATGGGGGCGACACTCCACCATGAATCACTCCCCTG...  ...            0.352828   \n",
      "1  CTTCACGCAGAAAGCGTCTAGCCATGGCGTTAGTATGAGTGTCGTG...  ...            0.387978   \n",
      "2  CCCCCCCTCCCGGGAGAGCCATAGTGGTCTGCGGAACCGGTGAGTA...  ...            0.409259   \n",
      "3  GGACGACCGGGTCCTTTCTTGGATCAACCCGCTCAATGCCTGGAGA...  ...            0.444020   \n",
      "4  CGCAAGACTGCTAGCCGAGTAGTGTTGGGTCGCGAAAGGCCTTGTG...  ...            0.462625   \n",
      "\n",
      "   normalized_coverage_per_sample  gc_alignment_region gc_probe_sequence  \\\n",
      "0                        0.352828            54.166667         58.333333   \n",
      "1                        0.387978            59.166667         60.833333   \n",
      "2                        0.409259            64.166667         63.333333   \n",
      "3                        0.444020            60.000000         59.166667   \n",
      "4                        0.462625            58.333333         58.333333   \n",
      "\n",
      "  gc_complementary hydrogen_bond_score  sample_id  viral_load  closest_ref  \\\n",
      "0        57.017544                 293    070-337    195214.0  1a_HQ850279   \n",
      "1        60.169492                 307    070-337    195214.0  1a_HQ850279   \n",
      "2        63.865546                 314    070-337    195214.0  1a_HQ850279   \n",
      "3        59.829060                 304    070-337    195214.0  1a_HQ850279   \n",
      "4        58.474576                 305    070-337    195214.0  1a_HQ850279   \n",
      "\n",
      "   q50_major_type  \n",
      "0              1a  \n",
      "1              1a  \n",
      "2              1a  \n",
      "3              1a  \n",
      "4              1a  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load the TSV file into a DataFrame\n",
    "all_probes_results_df = pd.read_csv(\n",
    "    \"../data_exports/forced_alignments_and_analysis_results_dataframe.tsv\", sep=\"\\t\"\n",
    ")\n",
    "\n",
    "print(all_probes_results_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Move relevant nucleotide frequency CSV files to another folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique run_id values:\n",
      "wtchgD00001556\n",
      "wtchgD00001562\n",
      "wtchgD00001561\n",
      "wtchgD00001576\n",
      "wtchgD00001577\n",
      "wtchgD00001567\n",
      "wtchgD00001558\n",
      "wtchgD00001555\n",
      "wtchgD00001560\n",
      "wtchgD00001575\n",
      "wtchgD00001559\n",
      "wtchgD00001557\n",
      "wtchgD00001571\n",
      "wtchgD00001583\n",
      "wtchgD00001582\n",
      "Copied ../azim_data/Summaries/T5/wtchgD00001556_closestdedup_vfat_QA_ntfreq_assem.txt to ../diversity_calculation/wtchgD00001556_closestdedup_vfat_QA_ntfreq_assem.txt\n",
      "Copied ../azim_data/Summaries/T5/wtchgD00001562_closestdedup_vfat_QA_ntfreq_assem.txt to ../diversity_calculation/wtchgD00001562_closestdedup_vfat_QA_ntfreq_assem.txt\n",
      "Copied ../azim_data/Summaries/T5/wtchgD00001561_closestdedup_vfat_QA_ntfreq_assem.txt to ../diversity_calculation/wtchgD00001561_closestdedup_vfat_QA_ntfreq_assem.txt\n",
      "Copied ../azim_data/Summaries/T5/wtchgD00001576_closestdedup_vfat_QA_ntfreq_assem.txt to ../diversity_calculation/wtchgD00001576_closestdedup_vfat_QA_ntfreq_assem.txt\n",
      "Copied ../azim_data/Summaries/T5/wtchgD00001577_closestdedup_vfat_QA_ntfreq_assem.txt to ../diversity_calculation/wtchgD00001577_closestdedup_vfat_QA_ntfreq_assem.txt\n",
      "Copied ../azim_data/Summaries/T5/wtchgD00001567_closestdedup_vfat_QA_ntfreq_assem.txt to ../diversity_calculation/wtchgD00001567_closestdedup_vfat_QA_ntfreq_assem.txt\n",
      "Copied ../azim_data/Summaries/T5/wtchgD00001558_closestdedup_vfat_QA_ntfreq_assem.txt to ../diversity_calculation/wtchgD00001558_closestdedup_vfat_QA_ntfreq_assem.txt\n",
      "Copied ../azim_data/Summaries/T5/wtchgD00001555_closestdedup_vfat_QA_ntfreq_assem.txt to ../diversity_calculation/wtchgD00001555_closestdedup_vfat_QA_ntfreq_assem.txt\n",
      "Copied ../azim_data/Summaries/T5/wtchgD00001560_closestdedup_vfat_QA_ntfreq_assem.txt to ../diversity_calculation/wtchgD00001560_closestdedup_vfat_QA_ntfreq_assem.txt\n",
      "Copied ../azim_data/Summaries/T5/wtchgD00001575_closestdedup_vfat_QA_ntfreq_assem.txt to ../diversity_calculation/wtchgD00001575_closestdedup_vfat_QA_ntfreq_assem.txt\n",
      "Copied ../azim_data/Summaries/T5/wtchgD00001559_closestdedup_vfat_QA_ntfreq_assem.txt to ../diversity_calculation/wtchgD00001559_closestdedup_vfat_QA_ntfreq_assem.txt\n",
      "Copied ../azim_data/Summaries/T5/wtchgD00001557_closestdedup_vfat_QA_ntfreq_assem.txt to ../diversity_calculation/wtchgD00001557_closestdedup_vfat_QA_ntfreq_assem.txt\n",
      "Copied ../azim_data/Summaries/T5/wtchgD00001571_closestdedup_vfat_QA_ntfreq_assem.txt to ../diversity_calculation/wtchgD00001571_closestdedup_vfat_QA_ntfreq_assem.txt\n",
      "Copied ../azim_data/Summaries/T5/wtchgD00001583_closestdedup_vfat_QA_ntfreq_assem.txt to ../diversity_calculation/wtchgD00001583_closestdedup_vfat_QA_ntfreq_assem.txt\n",
      "Copied ../azim_data/Summaries/T5/wtchgD00001582_closestdedup_vfat_QA_ntfreq_assem.txt to ../diversity_calculation/wtchgD00001582_closestdedup_vfat_QA_ntfreq_assem.txt\n",
      "File copying process completed.\n"
     ]
    }
   ],
   "source": [
    "# Get unique run_id values\n",
    "unique_run_ids = all_probes_results_df[\"run_id\"].unique()\n",
    "\n",
    "print(\"Unique run_id values:\")\n",
    "for run_id in unique_run_ids:\n",
    "    print(run_id)\n",
    "\n",
    "# Define the source and destination directories\n",
    "source_dir = \"../azim_data/Summaries/T5\"\n",
    "destination_dir = \"../diversity_calculation\"\n",
    "\n",
    "# Copy files for each unique run_id\n",
    "for run_id in unique_run_ids:\n",
    "    source_file = os.path.join(\n",
    "        source_dir, f\"{run_id}_closestdedup_vfat_QA_ntfreq_assem.txt\"\n",
    "    )\n",
    "    destination_file = os.path.join(\n",
    "        destination_dir, f\"{run_id}_closestdedup_vfat_QA_ntfreq_assem.txt\"\n",
    "    )\n",
    "\n",
    "    if os.path.exists(source_file):\n",
    "        try:\n",
    "            shutil.copy2(source_file, destination_file)\n",
    "            print(f\"Copied {source_file} to {destination_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error copying {source_file}: {str(e)}\")\n",
    "    else:\n",
    "        print(f\"File not found: {source_file}\")\n",
    "\n",
    "print(\"File copying process completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shannon entropy\n",
    "I think my shannon entropy calculation might be flawed because there might be a bug in how it accidentally accounts for insertions or deletions which I think I don't want. I decided that I am not interested in shannon entropy after all, however, so I won't bother fixing this.\n",
    "### One example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pos ConsensusNt  Read_Depth  FreqA  FreqT  FreqG  FreqC  FreqDel  \\\n",
      "0    1           C           7    0.0    0.0    0.0    1.0      0.0   \n",
      "1    2           C           8    0.0    0.0    0.0    1.0      0.0   \n",
      "2    3           C          10    0.0    0.0    0.0    1.0      0.0   \n",
      "3    4           T          10    0.0    1.0    0.0    0.0      0.0   \n",
      "4    5           G          10    0.0    0.0    1.0    0.0      0.0   \n",
      "\n",
      "  FreqInsertion Insertions(Count)  \n",
      "0           NaN               NaN  \n",
      "1           NaN               NaN  \n",
      "2           NaN               NaN  \n",
      "3           NaN               NaN  \n",
      "4           NaN               NaN  \n"
     ]
    }
   ],
   "source": [
    "# File path\n",
    "file_path = (\n",
    "    \"../diversity_calculation/wtchgD00001556_closestdedup_vfat_QA_ntfreq_assem.txt\"\n",
    ")\n",
    "\n",
    "# Read the file as a TSV into a DataFrame, skipping the first line\n",
    "nt_freq_wtchgD00001556 = pd.read_csv(file_path, sep=\"\\t\", skiprows=1)\n",
    "\n",
    "# Set the column names\n",
    "nt_freq_wtchgD00001556.columns = [\n",
    "    \"Pos\",\n",
    "    \"ConsensusNt\",\n",
    "    \"Read_Depth\",\n",
    "    \"FreqA\",\n",
    "    \"FreqT\",\n",
    "    \"FreqG\",\n",
    "    \"FreqC\",\n",
    "    \"FreqDel\",\n",
    "    \"FreqInsertion\",\n",
    "    \"Insertions(Count)\",\n",
    "]\n",
    "\n",
    "print(nt_freq_wtchgD00001556.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculate_shannon_entropy(row):\n",
    "#     frequencies = [row[\"FreqA\"], row[\"FreqT\"], row[\"FreqG\"], row[\"FreqC\"]]\n",
    "#     # Check if all frequencies are either 0 or 1\n",
    "#     if all(f in [0, 1] for f in frequencies):\n",
    "#         return 0\n",
    "#     # Remove zero frequencies to avoid log(0)\n",
    "#     frequencies = [f for f in frequencies if f > 0]\n",
    "#     # Calculate entropy\n",
    "#     entropy = -sum(f * np.log2(f) for f in frequencies)\n",
    "#     return max(0, entropy)  # Ensure non-negative value\n",
    "\n",
    "\n",
    "# # Calculate Shannon entropy for each position\n",
    "# nt_freq_wtchgD00001556[\"shannon_entropy\"] = nt_freq_wtchgD00001556.apply(\n",
    "#     calculate_shannon_entropy, axis=1\n",
    "# )\n",
    "\n",
    "# # Print the first few rows to verify the new column\n",
    "# print(nt_freq_wtchgD00001556.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correspond to original data frame, only one row first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1. Get the run_id for the first row\n",
    "# first_row = all_probes_results_df.iloc[0]\n",
    "# run_id = first_row[\"run_id\"]\n",
    "\n",
    "# # 3. Convert Shannon entropy values to a list\n",
    "# shannon_entropy_list = nt_freq_wtchgD00001556[\"shannon_entropy\"].tolist()\n",
    "# print(f\"Length of Shannon entropy list: {len(shannon_entropy_list)}\")\n",
    "\n",
    "# # 4. Access the numbers in base_reference_read_position_list\n",
    "# base_positions = eval(first_row[\"base_reference_read_position_list\"])\n",
    "# print(f\"base_reference_read_position_list in first row: {base_positions}\")\n",
    "\n",
    "# # 5. Use those numbers to access the corresponding Shannon entropy values\n",
    "# shannon_entropy_values = [\n",
    "#     shannon_entropy_list[pos - 1] if pos is not None and pos > 0 else np.nan\n",
    "#     for pos in base_positions\n",
    "# ]\n",
    "# print(f\"corresponding shannon_entropy_values: {shannon_entropy_values}\")\n",
    "\n",
    "# # 6. Add the Shannon entropy values to the DataFrame\n",
    "# all_probes_results_df[\"shannon_entropy\"] = np.nan  # Initialize the column with NaN\n",
    "# all_probes_results_df.at[0, \"shannon_entropy\"] = str(\n",
    "#     shannon_entropy_values\n",
    "# )  # Convert to string for storage\n",
    "\n",
    "# # 7. Check if the lengths match\n",
    "# base_list_length = len(base_positions)\n",
    "# shannon_list_length = len(shannon_entropy_values)\n",
    "# print(f\"Length of base_reference_read_position_list: {base_list_length}\")\n",
    "# print(f\"Length of shannon_entropy list: {shannon_list_length}\")\n",
    "# print(f\"Lengths match: {base_list_length == shannon_list_length}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nucleotide diversity instead of shannon entropy\n",
    "After coding the above, I decided that actually nucleotide diversity is a better measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row data for position 139:\n",
      "Pos                          139\n",
      "ConsensusNt                    G\n",
      "Read_Depth                    28\n",
      "FreqA                   0.035714\n",
      "FreqT                        0.0\n",
      "FreqG                   0.964286\n",
      "FreqC                        0.0\n",
      "FreqDel                      0.0\n",
      "FreqInsertion                NaN\n",
      "Insertions(Count)            NaN\n",
      "nucleotide_diversity    0.071429\n",
      "Name: 138, dtype: object\n",
      "\n",
      "Step-by-step calculation:\n",
      "Read depth: 28\n",
      "A count: 1\n",
      "T count: 0\n",
      "G count: 27\n",
      "C count: 0\n",
      "\n",
      "Total count (n): 28\n",
      "Sum of pairwise products: 27\n",
      "Denominator: 378.0\n",
      "Nucleotide diversity (d): 0.07142857142857142\n"
     ]
    }
   ],
   "source": [
    "# Nick shared this function for calculating nucleotide diversity:\n",
    "def calculate_d_for_pie_diversity(a_count, t_count, c_count, g_count):\n",
    "    n = a_count + c_count + g_count + t_count\n",
    "    if n <= 1:\n",
    "        return None\n",
    "    ac = a_count * c_count\n",
    "    at = a_count * t_count\n",
    "    ag = a_count * g_count\n",
    "    tc = t_count * c_count\n",
    "    tg = t_count * g_count\n",
    "    cg = c_count * g_count\n",
    "    sum_nucs = ac + at + ag + tc + tg + cg\n",
    "    n_half = n / 2.0\n",
    "    denominator = n_half * (n - 1)\n",
    "    if denominator != 0:\n",
    "        d = sum_nucs / denominator\n",
    "    else:\n",
    "        return None  # Slight modification from the original function: instead of raising an error, return None for zero denominator\n",
    "    return d\n",
    "\n",
    "\n",
    "# Adapt the above function to work with the data format I have\n",
    "def apply_nucleotide_diversity(row):\n",
    "    total_depth = row[\"Read_Depth\"]\n",
    "    a_count = round(row[\"FreqA\"] * total_depth)\n",
    "    t_count = round(row[\"FreqT\"] * total_depth)\n",
    "    g_count = round(row[\"FreqG\"] * total_depth)\n",
    "    c_count = round(row[\"FreqC\"] * total_depth)\n",
    "    return calculate_d_for_pie_diversity(a_count, t_count, c_count, g_count)\n",
    "\n",
    "\n",
    "# Apply the function to each row of your DataFrame\n",
    "nt_freq_wtchgD00001556[\"nucleotide_diversity\"] = nt_freq_wtchgD00001556.apply(\n",
    "    apply_nucleotide_diversity, axis=1\n",
    ")\n",
    "\n",
    "# Sanity checking whether calculation is working as intended\n",
    "\n",
    "# Print the row where Pos = 139\n",
    "row_139 = nt_freq_wtchgD00001556[nt_freq_wtchgD00001556[\"Pos\"] == 139].iloc[0]\n",
    "print(\"Row data for position 139:\")\n",
    "print(row_139)\n",
    "\n",
    "# Now let's calculate nucleotide diversity step by step\n",
    "read_depth = row_139[\"Read_Depth\"]\n",
    "a_count = round(row_139[\"FreqA\"] * read_depth)\n",
    "t_count = round(row_139[\"FreqT\"] * read_depth)\n",
    "g_count = round(row_139[\"FreqG\"] * read_depth)\n",
    "c_count = round(row_139[\"FreqC\"] * read_depth)\n",
    "\n",
    "print(\"\\nStep-by-step calculation:\")\n",
    "print(f\"Read depth: {read_depth}\")\n",
    "print(f\"A count: {a_count}\")\n",
    "print(f\"T count: {t_count}\")\n",
    "print(f\"G count: {g_count}\")\n",
    "print(f\"C count: {c_count}\")\n",
    "\n",
    "# Calculate nucleotide diversity\n",
    "n = a_count + t_count + g_count + c_count\n",
    "print(f\"\\nTotal count (n): {n}\")\n",
    "\n",
    "if n <= 1:\n",
    "    print(\"Nucleotide diversity is None (n <= 1)\")\n",
    "else:\n",
    "    ac = a_count * c_count\n",
    "    at = a_count * t_count\n",
    "    ag = a_count * g_count\n",
    "    tc = t_count * c_count\n",
    "    tg = t_count * g_count\n",
    "    cg = c_count * g_count\n",
    "    sum_nucs = ac + at + ag + tc + tg + cg\n",
    "    print(f\"Sum of pairwise products: {sum_nucs}\")\n",
    "\n",
    "    n_half = n / 2.0\n",
    "    denominator = n_half * (n - 1)\n",
    "    print(f\"Denominator: {denominator}\")\n",
    "\n",
    "    if denominator != 0:\n",
    "        d = sum_nucs / denominator\n",
    "        print(f\"Nucleotide diversity (d): {d}\")\n",
    "    else:\n",
    "        print(\"Nucleotide diversity is None (denominator = 0)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working through one example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of nucleotide diversity list: 9378\n",
      "base_reference_read_position_list in first row: [None, None, None, None, None, None, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114]\n",
      "corresponding nucleotide_diversity_values: [nan, nan, nan, nan, nan, nan, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11764705882352941, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1476923076923077, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Length of base_reference_read_position_list: 120\n",
      "Length of nucleotide_diversity list: 120\n",
      "Lengths match: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/th/lqlr4bd14y70d5dlhczfj2v40000gn/T/ipykernel_70276/1637260296.py:30: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[nan, nan, nan, nan, nan, nan, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11764705882352941, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1476923076923077, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  all_probes_results_df.at[0, \"nucleotide_diversity\"] = str(\n"
     ]
    }
   ],
   "source": [
    "# 1. Get the run_id for the first row\n",
    "first_row = all_probes_results_df.iloc[0]\n",
    "run_id = first_row[\"run_id\"]\n",
    "\n",
    "nt_freq_wtchgD00001556[\"nucleotide_diversity\"] = nt_freq_wtchgD00001556.apply(\n",
    "    apply_nucleotide_diversity, axis=1\n",
    ")\n",
    "\n",
    "# 3. Convert nucleotide diversity values to a list\n",
    "nucleotide_diversity_list = nt_freq_wtchgD00001556[\"nucleotide_diversity\"].tolist()\n",
    "print(f\"Length of nucleotide diversity list: {len(nucleotide_diversity_list)}\")\n",
    "\n",
    "# 4. Access the numbers in base_reference_read_position_list\n",
    "base_positions = eval(first_row[\"base_reference_read_position_list\"])\n",
    "print(f\"base_reference_read_position_list in first row: {base_positions}\")\n",
    "\n",
    "# 5. Use those numbers to access the corresponding nucleotide diversity values\n",
    "nucleotide_diversity_values = [\n",
    "    (\n",
    "        nucleotide_diversity_list[pos - 1]\n",
    "        if pos is not None and pos > 0 and pos <= len(nucleotide_diversity_list)\n",
    "        else np.nan\n",
    "    )\n",
    "    for pos in base_positions\n",
    "]\n",
    "print(f\"corresponding nucleotide_diversity_values: {nucleotide_diversity_values}\")\n",
    "\n",
    "# 6. Add the nucleotide diversity values to the DataFrame\n",
    "all_probes_results_df[\"nucleotide_diversity\"] = np.nan  # Initialize the column with NaN\n",
    "all_probes_results_df.at[0, \"nucleotide_diversity\"] = str(\n",
    "    nucleotide_diversity_values\n",
    ")  # Convert to string for storage\n",
    "\n",
    "# 7. Calculate and add the average nucleotide diversity\n",
    "avg_diversity = np.nanmean(nucleotide_diversity_values)\n",
    "all_probes_results_df[\"avg_nucleotide_diversity\"] = (\n",
    "    np.nan\n",
    ")  # Initialize the column with NaN\n",
    "all_probes_results_df.at[0, \"avg_nucleotide_diversity\"] = avg_diversity\n",
    "\n",
    "# 8. Check if the lengths match\n",
    "base_list_length = len(base_positions)\n",
    "diversity_list_length = len(nucleotide_diversity_values)\n",
    "print(f\"Length of base_reference_read_position_list: {base_list_length}\")\n",
    "print(f\"Length of nucleotide_diversity list: {diversity_list_length}\")\n",
    "print(f\"Lengths match: {base_list_length == diversity_list_length}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generalising to all rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positions where diversity couldn't be calculated: 1\n",
      "Number of positions where diversity couldn't be calculated: 2\n",
      "Number of positions where diversity couldn't be calculated: 1\n",
      "Number of positions where diversity couldn't be calculated: 2\n",
      "Number of positions where diversity couldn't be calculated: 2\n",
      "Number of positions where diversity couldn't be calculated: 9\n",
      "Number of positions where diversity couldn't be calculated: 2\n",
      "Number of positions where diversity couldn't be calculated: 2\n",
      "Number of positions where diversity couldn't be calculated: 2\n",
      "Number of positions where diversity couldn't be calculated: 1\n",
      "Number of positions where diversity couldn't be calculated: 3\n",
      "Number of positions where diversity couldn't be calculated: 85\n",
      "Number of positions where diversity couldn't be calculated: 2\n",
      "Number of positions where diversity couldn't be calculated: 54\n",
      "Number of positions where diversity couldn't be calculated: 8\n",
      "Efficient nucleotide diversity calculation completed for all rows.\n",
      "           run_id                               nucleotide_diversity  \\\n",
      "0  wtchgD00001556  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "1  wtchgD00001556  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "2  wtchgD00001556  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "3  wtchgD00001556  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "4  wtchgD00001556  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.066...   \n",
      "\n",
      "   avg_nucleotide_diversity  \n",
      "0                  0.002328  \n",
      "1                  0.002422  \n",
      "2                  0.003269  \n",
      "3                  0.003249  \n",
      "4                  0.003174  \n"
     ]
    }
   ],
   "source": [
    "# Modifying the original function to work with numpy arrays to make computations more efficient\n",
    "def calculate_d_for_pie_diversity(a_count, t_count, c_count, g_count):\n",
    "    # Calculate total count of nucleotides\n",
    "    n = a_count + c_count + g_count + t_count\n",
    "\n",
    "    # Calculate sum of pairwise products\n",
    "    # This is equivalent to the original individual calculations (ac, at, ag, tc, tg, cg)\n",
    "    sum_nucs = (\n",
    "        a_count * c_count\n",
    "        + a_count * t_count\n",
    "        + a_count * g_count\n",
    "        + t_count * c_count\n",
    "        + t_count * g_count\n",
    "        + c_count * g_count\n",
    "    )\n",
    "\n",
    "    # Calculate denominator\n",
    "    denominator = (n / 2.0) * (n - 1)\n",
    "\n",
    "    # Suppress RuntimeWarnings that may occur during division\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "        # Vectorized calculation of diversity\n",
    "        # np.where is used instead of if-else for vectorized operations\n",
    "        # It returns np.nan when n <= 1 or denominator == 0, equivalent to returning None in the original\n",
    "        result = np.where((n > 1) & (denominator != 0), sum_nucs / denominator, np.nan)\n",
    "\n",
    "    # Log the number of positions where diversity couldn't be calculated\n",
    "    nan_count = np.isnan(result).sum()\n",
    "    if nan_count > 0:\n",
    "        print(\n",
    "            f\"Number of positions where diversity couldn't be calculated: {nan_count}\"\n",
    "        )\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def process_run_id(run_id, diversity_dir, base_positions_dict):\n",
    "    file_path = os.path.join(\n",
    "        diversity_dir, f\"{run_id}_closestdedup_vfat_QA_ntfreq_assem.txt\"\n",
    "    )\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"File not found for run_id {run_id}: {file_path}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Read the file using csv.reader to handle potential formatting issues\n",
    "    with open(file_path, \"r\") as f:\n",
    "        reader = csv.reader(f, delimiter=\"\\t\")\n",
    "        next(reader)  # Skip the header row\n",
    "        data = []\n",
    "        for row in reader:\n",
    "            if len(row) >= 7:  # Ensure we have at least the columns we need\n",
    "                data.append(row[:7])  # Only take the first 7 columns\n",
    "            else:\n",
    "                print(f\"Skipping malformed row in file for run_id {run_id}: {row}\")\n",
    "\n",
    "    # Create DataFrame from the cleaned data\n",
    "    columns = [\"Pos\", \"ConsensusNt\", \"Read_Depth\", \"FreqA\", \"FreqT\", \"FreqG\", \"FreqC\"]\n",
    "    nt_freq_df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "    # Convert columns to appropriate types\n",
    "    nt_freq_df[\"Pos\"] = pd.to_numeric(nt_freq_df[\"Pos\"], errors=\"coerce\")\n",
    "    nt_freq_df[\"Read_Depth\"] = pd.to_numeric(nt_freq_df[\"Read_Depth\"], errors=\"coerce\")\n",
    "    for col in [\"FreqA\", \"FreqT\", \"FreqG\", \"FreqC\"]:\n",
    "        nt_freq_df[col] = pd.to_numeric(nt_freq_df[col], errors=\"coerce\")\n",
    "\n",
    "    # Calculate nucleotide diversity\n",
    "    read_depth = np.nan_to_num(\n",
    "        nt_freq_df[\"Read_Depth\"].values, nan=0, posinf=0, neginf=0\n",
    "    )\n",
    "    a_count = np.round(\n",
    "        np.nan_to_num(nt_freq_df[\"FreqA\"].values, nan=0, posinf=0, neginf=0)\n",
    "        * read_depth\n",
    "    ).astype(int)\n",
    "    t_count = np.round(\n",
    "        np.nan_to_num(nt_freq_df[\"FreqT\"].values, nan=0, posinf=0, neginf=0)\n",
    "        * read_depth\n",
    "    ).astype(int)\n",
    "    g_count = np.round(\n",
    "        np.nan_to_num(nt_freq_df[\"FreqG\"].values, nan=0, posinf=0, neginf=0)\n",
    "        * read_depth\n",
    "    ).astype(int)\n",
    "    c_count = np.round(\n",
    "        np.nan_to_num(nt_freq_df[\"FreqC\"].values, nan=0, posinf=0, neginf=0)\n",
    "        * read_depth\n",
    "    ).astype(int)\n",
    "\n",
    "    nt_freq_df[\"nucleotide_diversity\"] = calculate_d_for_pie_diversity(\n",
    "        a_count, t_count, g_count, c_count\n",
    "    )\n",
    "\n",
    "    results = []\n",
    "    for idx, base_positions in base_positions_dict[run_id].items():\n",
    "        nucleotide_diversity_values = nt_freq_df.loc[\n",
    "            nt_freq_df[\"Pos\"].isin(base_positions), \"nucleotide_diversity\"\n",
    "        ].tolist()\n",
    "\n",
    "        avg_diversity = np.nanmean(nucleotide_diversity_values)\n",
    "        results.append(\n",
    "            {\n",
    "                \"run_id\": run_id,\n",
    "                \"index\": idx,\n",
    "                \"nucleotide_diversity\": str(nucleotide_diversity_values),\n",
    "                \"avg_nucleotide_diversity\": avg_diversity,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "# Prepare a dictionary of base positions for each run_id\n",
    "base_positions_dict = {}\n",
    "for idx, row in all_probes_results_df.iterrows():\n",
    "    run_id = row[\"run_id\"]\n",
    "    if run_id not in base_positions_dict:\n",
    "        base_positions_dict[run_id] = {}\n",
    "    base_positions_dict[run_id][idx] = eval(row[\"base_reference_read_position_list\"])\n",
    "\n",
    "\n",
    "# Process each unique run_id\n",
    "diversity_dir = \"../diversity_calculation\"\n",
    "unique_run_ids = all_probes_results_df[\"run_id\"].unique()\n",
    "results = pd.concat(\n",
    "    [\n",
    "        process_run_id(run_id, diversity_dir, base_positions_dict)\n",
    "        for run_id in unique_run_ids\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Merge results back to the original DataFrame\n",
    "results.set_index(\"index\", inplace=True)\n",
    "\n",
    "# Remove existing columns if they exist\n",
    "columns_to_update = [\"nucleotide_diversity\", \"avg_nucleotide_diversity\"]\n",
    "for col in columns_to_update:\n",
    "    if col in all_probes_results_df.columns:\n",
    "        all_probes_results_df = all_probes_results_df.drop(columns=[col])\n",
    "\n",
    "# Now join the new results\n",
    "all_probes_results_df = all_probes_results_df.join(results[columns_to_update])\n",
    "\n",
    "print(\"Efficient nucleotide diversity calculation completed for all rows.\")\n",
    "print(\n",
    "    all_probes_results_df[\n",
    "        [\"run_id\", \"nucleotide_diversity\", \"avg_nucleotide_diversity\"]\n",
    "    ].head()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save dataframe to share with colleagues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the updated DataFrame\n",
    "all_probes_results_df.to_csv(\n",
    "    \"../data_exports/updated_forced_alignments_analysis_with_nucleotide_diversity_all_probes_results_df.tsv\",\n",
    "    sep=\"\\t\",\n",
    "    index=False,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
